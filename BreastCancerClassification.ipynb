{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BreastCancerClassification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMxwT364THa6hLfR8u6acwE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"8qoQ9Lw1Zke7","executionInfo":{"status":"ok","timestamp":1624691904014,"user_tz":-360,"elapsed":545,"user":{"displayName":"Armanul Islam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfGWDaztDqTROIadMp2lJe7uFFeCQKiFZcU5Kn=s64","userId":"14103268323063574381"}}},"source":["from google.colab import files"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":38},"id":"mpsBe8OQclu7","outputId":"b33c871a-8fb1-45a3-87b9-aa3514b220ce"},"source":["uploaded = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-3ef83e96-a7f4-40a2-afa9-b346445f3675\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-3ef83e96-a7f4-40a2-afa9-b346445f3675\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"pxUs2jn1ciH5"},"source":["\n","\n","\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fb1g-hdicu2r"},"source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x3GzQh8wFl10"},"source":["DATA ANALYSIS"]},{"cell_type":"code","metadata":{"id":"vi2nwo9FcyzR"},"source":["df=pd.read_csv('data.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bUAfRq9edA-n"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LtTIUvvQdsdV"},"source":["df.columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qaY7pFsKdv4u"},"source":["#Drop the column with all missing values (na, NAN, NaN)\n","#NOTE: This drops the column Unnamed: 32 column\n","df = df.dropna(axis=1)\n","#Get a count of the number of 'M' & 'B' cells\n","df['diagnosis'].value_counts()\n","#Visualize this count \n","sns.countplot(df['diagnosis'],label=\"Count\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1zHqteLqeog9"},"source":["# y includes diagnosis column with M or B values\n","y = df.diagnosis\n","# drop the column 'id' as it is does not convey any useful info\n","# drop diagnosis since we are separating labels and features \n","list = [\"id\",\"diagnosis\"]\n","# X includes our features\n","X = df.drop(list,axis = 1)\n","# get the first ten features\n","print(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G0tUKjv3gPcd"},"source":["data = X.select_dtypes(float)\n","data_dia = y\n","data = X\n","data_std =(data-data.mean())/(data.std()) # standardization\n","# get the first 10 features\n","data = pd.concat([y,data_std.iloc[:,0:10]],axis=1)\n","data = pd.melt(data,id_vars=\"diagnosis\",\n"," var_name=\"features\",\n"," value_name='value')\n","# make a violin plot\n","plt.figure(figsize=(10,10))\n","sns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data,split=True, inner=\"quart\")\n","plt.xticks(rotation=90)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4znxTV81hcre"},"source":["#correlation map\n","f,ax = plt.subplots(figsize=(18, 18))\n","matrix = np.triu(X.corr())\n","sns.heatmap(X.corr(), annot=True, linewidths=.5, fmt= \".1f\",ax=ax, mask=matrix)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RmDnwCw3iKkb"},"source":["# create boxplots for texture mean vs diagnosis of tumor\n","plot = sns.boxplot(x='diagnosis', y='texture_mean', data=df, showfliers=False)\n","plot.set_title(\"Graph of texture mean vs diagnosis of tumor\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J89V161LifVQ"},"source":["from scipy import stats\n","# make a new dataframe with only the desired feature for t test  \n","new = pd.DataFrame(data=df[['area_worst', 'diagnosis']])\n","new = new.set_index('diagnosis')\n","stats.ttest_ind(new.loc['M'], new.loc['B'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMo7ASS9kMj8"},"source":["# Create correlation matrix\n","corr_matrix = X.corr().abs()\n","# Select upper triangle of correlation matrix\n","upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n","# Find index of feature columns with correlation greater than 0.95\n","to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n","# Drop features \n","X = X.drop(X[to_drop], axis=1)\n","X.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BaWHTs1VF-6r"},"source":["MACHINE LEARNING"]},{"cell_type":"markdown","metadata":{"id":"vu0TYmACG-qN"},"source":["TRANSFORM CATEGORICAL VARIABLES"]},{"cell_type":"code","metadata":{"id":"AY6yTEOYkX60"},"source":["#Encoding categorical data values\n","from sklearn.preprocessing import LabelEncoder\n","labelencoder_y = LabelEncoder()\n","y= labelencoder_y.fit_transform(y)\n","print(labelencoder_y.fit_transform(y))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9C_xf6uPHM7P"},"source":["TRAIN TEST SPLIT THE DATA"]},{"cell_type":"code","metadata":{"id":"Gxn0VAYCkalE"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, stratify=y, random_state = 17)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZfHZx5-8HYsV"},"source":["FEATURE SCALING"]},{"cell_type":"code","metadata":{"id":"K6zhaQRTkhKm"},"source":["#Feature Scaling\n","from sklearn.preprocessing import RobustScaler\n","sc = RobustScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JkgF9OPRHfOa"},"source":["TRAIN THE DATA"]},{"cell_type":"code","metadata":{"id":"oM-lKzm5kllp"},"source":["# Define a function which trains models\n","def models(X_train,y_train):\n","    \n","  #Using Logistic Regression \n","    from sklearn.linear_model import LogisticRegression\n","    log = LogisticRegression(random_state = 0)\n","    log.fit(X_train, y_train)\n","  #Using SVC linear\n","    from sklearn.svm import SVC\n","    svc_lin = SVC(kernel = 'linear', random_state = 0)\n","    svc_lin.fit(X_train, y_train)\n","  #Using SVC rbf\n","    from sklearn.svm import SVC\n","    svc_rbf = SVC(kernel = 'rbf', random_state = 0)\n","    svc_rbf.fit(X_train, y_train)\n","  #Using DecisionTreeClassifier \n","    from sklearn.tree import DecisionTreeClassifier\n","    tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n","    tree.fit(X_train, y_train)\n","  #Using Random Forest Classifier\n","    from sklearn.ensemble import RandomForestClassifier\n","    forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n","    forest.fit(X_train, y_train)\n","  \n","  #print model accuracy on the training data.\n","    print('[0]Logistic Regression Training Accuracy:', log.score(X_train, y_train))\n","    print('[1]Support Vector Machine (Linear Classifier) Training Accuracy:', svc_lin.score(X_train, y_train))\n","    print('[2]Support Vector Machine (RBF Classifier) Training Accuracy:', svc_rbf.score(X_train, y_train))\n","    print('[3]Decision Tree Classifier Training Accuracy:', tree.score(X_train, y_train))\n","    print('[4]Random Forest Classifier Training Accuracy:', forest.score(X_train, y_train))\n","  \n","    return log, svc_lin, svc_rbf, tree, forest\n","#get the training results\n","model = models(X_train,y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oEsRT1TDHkG5"},"source":["CONFUSION MATRIX"]},{"cell_type":"code","metadata":{"id":"xeH0bXOTkncz"},"source":["from sklearn.metrics import confusion_matrix\n","for i in range(len(model)):\n"," \n"," cm = confusion_matrix(y_test, model[i].predict(X_test))\n"," \n"," TN = cm[0][0]\n"," TP = cm[1][1]\n"," FN = cm[1][0]\n"," FP = cm[0][1]\n"," \n"," print(cm)\n"," print('Model[{}] Testing Accuracy = \"{}\"'.format(i, (TP + TN) / (TP + TN + FN + FP)))\n"," print()# Print a new line"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kBkDbchkHpxh"},"source":["CLASSIFICATION REPORT"]},{"cell_type":"code","metadata":{"id":"6S67yvLWk7py"},"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","for i in range(len(model)):\n"," print('Model ',i)\n"," #Check precision, recall, f1-score\n"," print(classification_report(y_test, model[i].predict(X_test)))\n"," #Another way to get the models accuracy on the test data\n"," print(accuracy_score(y_test, model[i].predict(X_test)))\n"," print()#Print a new line"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9DuFpIKBlBQi"},"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","#make the scoring function with a beta = 2\n","from sklearn.metrics import fbeta_score, make_scorer\n","ftwo_scorer = make_scorer(fbeta_score, beta=2)\n","# Create logistic regression\n","logistic = LogisticRegression()\n","# Create regularization penalty space\n","penalty = ['l1', 'l2']\n","# Create regularization hyperparameter space\n","C = np.arange(0, 1, 0.001)\n","# Create hyperparameter options\n","hyperparameters = dict(C=C, penalty=penalty)\n","# Create grid search using 5-fold cross validation\n","clf = GridSearchCV(logistic, hyperparameters, cv=5, scoring=ftwo_scorer, verbose=0)\n","# Fit grid search\n","best_model = clf.fit(X_train, y_train)\n","# View best hyperparameters\n","print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n","print('Best C:', best_model.best_estimator_.get_params()['C'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nbEGNJNllIt"},"source":["predictions = best_model.predict(X_test)\n","print(\"Accuracy score %f\" % accuracy_score(y_test, predictions))\n","print(classification_report(y_test, predictions))\n","print(confusion_matrix(y_test, predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZQhTwy3pII5K"},"source":["CUSTOM THRESHOLD TO INCREASE RECALL"]},{"cell_type":"code","metadata":{"id":"UQMnY7fzlsj6"},"source":["y_scores = best_model.predict_proba(X_test)[:, 1]\n","from sklearn.metrics import precision_recall_curve\n","p, r, thresholds = precision_recall_curve(y_test, y_scores)\n","def adjusted_classes(y_scores, t):\n","#This function adjusts class predictions based on the prediction threshold (t).Works only for binary classification problems.\n","    return [1 if y >= t else 0 for y in y_scores]\n","def precision_recall_threshold(p, r, thresholds, t=0.5):\n","    #plots the precision recall curve and shows the current value           for each by identifying the classifier's threshold (t).\n","    \n","    # generate new class predictions based on the adjusted classes\n","    #function above and view the resulting confusion matrix.\n","    y_pred_adj = adjusted_classes(y_scores, t)\n","    print(pd.DataFrame(confusion_matrix(y_test, y_pred_adj),\n","                       columns=['pred_neg', 'pred_pos'], \n","                       index=['neg', 'pos']))\n","    print(classification_report(y_test, y_pred_adj))\n","precision_recall_threshold(p, r, thresholds, 0.42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IJPEA2_kIrGZ"},"source":["GRAPH OF RECALL AND PRECISION VS THRESHOLD"]},{"cell_type":"code","metadata":{"id":"fnWhmiArl5sN"},"source":["def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n"," \n"," plt.figure(figsize=(8, 8))\n"," plt.title(\"Recall Scores as a function of the decision threshold\")\n"," plt.plot(thresholds, precisions[:-1], \"b-\", label=\"Precision\")\n"," plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n"," plt.axvline(x=.42, color='black')\n"," plt.text(.39,.50,'Optimal Threshold for best Recall',rotation=90)\n"," plt.ylabel(\"Recall Score\")\n"," plt.xlabel(\"Decision Threshold\")\n"," plt.legend(loc='best')\n","# use the same p, r, thresholds that were previously calculated\n","plot_precision_recall_vs_threshold(p, r, thresholds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"53aaaYl1mgva"},"source":["from sklearn import metrics\n","from sklearn.metrics import roc_curve\n","# Compute predicted probabilities: y_pred_prob\n","y_pred_prob = best_model.predict_proba(X_test)[:,1]\n","# Generate ROC curve values: fpr, tpr, thresholds\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n","print(metrics.auc(fpr, tpr))\n","# Plot ROC curve\n","plt.plot([0, 1], [0, 1], 'k-')\n","plt.plot(fpr, tpr)\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve for Logistic Regression')\n","plt.show()"],"execution_count":null,"outputs":[]}]}